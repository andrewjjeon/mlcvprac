# To install packages that aren't installed by default, uncomment the last two lines of this cell 
# and replace <package list> with a list of packages.
# This will ensure the notebook has all the dependencies and works everywhere.

import sys
get_ipython().getoutput("{sys.executable} -m pip install <package list>")


#Libraries
import pandas as pd
pd.set_option("display.max_columns", 101)


# Dataset is already loaded below
data = pd.read_csv("train.csv")


data.head()


#Explore columns
data.columns


#Description
data.describe()





#Loading Test data
test_data=pd.read_csv('test.csv')
test_data.head()


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

#list of all features
features = data.columns.tolist()
#remove our y from our dataset
features.remove("is_authentic")

target = "is_authentic"



#Preprocess categorical features
categorical_features = ["title", "location", "department", "industry", "salary_range",
                        "employment_type", "required_experience", "required_education"]

print(data.columns)
print(categorical_features)

#we have to encode our string features into encoded integers so we can run our randomforest model on the data
label_encoders = {}
for feature in categorical_features:
    label_encoders[feature] = LabelEncoder()
    data[feature] = label_encoders[feature].fit_transform(data[feature].astype(str))

numerical_features = ["work_from_home", "company_logo", "screening_round"]
#deal with missing values by just replacing with median value of that column
data[numerical_features] = data[numerical_features].fillna(data[numerical_features].median())


print(data.columns)

#Split data into train and validation sets
X, y = data[features], data[target]
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)

#Scale/normalize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

#Finally, train the model, I picked a RandomForestClassifier due to the categorical nature of the data
model = RandomForestClassifier()
model.fit(X_train_scaled, y_train)

#Visualize an accuracy score on the validation set
y_pred = model.predict(X_val_scaled)
accuracy = accuracy_score(y_val, y_pred)
print(f"Accuracy: {accuracy}")


import matplotlib.pyplot as plt

importances = model.feature_importances_ # this is an attribute of the model that returns and array containing the importance value of each feature

plt.figure(figsize=(10, 6))
plt.barh(range(len(features)), importances, align='center')  #barh because regular bar is hard to see all the feature names
plt.yticks(range(len(features)), features)
plt.xlabel('Feature Importance')
plt.ylabel('Features')
plt.title('Feature Importances')
plt.show()


for feature in categorical_features:
    test_data[feature] = label_encoders[feature].fit_transform(test_data[feature].astype(str))
    
test_data[numerical_features] = data[numerical_features].fillna(data[numerical_features].median())

X_test_scaled = scaler.transform(test_data[features])

test_predictions = model.predict(X_test_scaled)

submissions_df = pd.DataFrame({'id': test_data['id'], 'is_authentic': test_predictions})

submissions_df.to_csv('submissions.csv',index=False)
